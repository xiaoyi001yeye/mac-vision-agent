# macOS 视觉智能体系统用例图 (功能验证版)

## 核心用例图

```mermaid
graph TB
    subgraph "macOS 视觉智能体系统"
        UC1[执行桌面任务]
        UC2[屏幕内容理解]
        UC3[自动化操作]
    end
    
    User[用户]
    macOS[macOS系统]
    
    User --> UC1
    UC1 ..> UC2 : include
    UC1 ..> UC3 : include
    UC2 --> macOS
    UC3 --> macOS
```

## 核心用例描述

### UC1: 执行桌面任务
- **输入**: 用户自然语言指令
- **输出**: 任务执行结果
- **流程**: 指令解析 → 屏幕理解 → 操作执行 → 结果反馈

### UC2: 屏幕内容理解
- **功能**: 捕获屏幕截图，使用VLM理解内容
- **技术**: ScreenCaptureKit + VLM模型
- **输出**: 屏幕语义描述和可交互元素识别

### UC3: 自动化操作
- **功能**: 执行鼠标键盘操作
- **技术**: PyAutoGUI 或 Quartz Event Services
- **操作**: 点击、输入、滚动等基础交互

## 验证重点

### 技术可行性验证
1. **屏幕捕获**: ScreenCaptureKit API 集成
2. **VLM集成**: 本地模型推理能力
3. **自动化操作**: 系统权限和操作精度
4. **端到端流程**: 完整的感知-决策-执行循环

### 最小验证场景
- 简单应用启动 (如打开计算器)
- 基础UI交互 (如点击按钮)
- 文本输入操作

### 技术约束
- macOS 12.3+
- 需要辅助功能和屏幕录制权限
- Apple Silicon Mac 设备